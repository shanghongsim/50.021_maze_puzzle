{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import math\n",
    "from datasets import Dataset, Features, Array2D, Value, load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 3)\n",
      "{'data': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1],\n",
      "        [1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'filename': '11HnKgridsize_1_step0_DOWN', 'label': tensor(4)}\n"
     ]
    }
   ],
   "source": [
    "loaded_data = load_from_disk(\n",
    "        \"/Users/yijiachen/Desktop/50.021 Artificial Intelligence/Project/code/code-repo/dataset/even_label/11x11_train.hf\"\n",
    "    ).with_format(\"torch\")\n",
    "\n",
    "print(loaded_data.shape)\n",
    "print(loaded_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_set_size = math.floor(0.8*loaded_data.shape[0])\n",
    "train_set, val_set = torch.utils.data.random_split(loaded_data, [train_set_size, loaded_data.shape[0] - train_set_size])\n",
    "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "\n",
    "classes = ('END', 'LEFT', 'RIGHT', 'UP', 'DOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor(2), tensor(1), tensor(4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAACYCAYAAAA2uOkuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANlElEQVR4nO3dQWib9R/H8U/a0ThHlyKbScM6rVARFStMWgp6WqBUGFNQdHgoO+jFHbR4sGDbCULLhrNsFHuS4WWbF+tFdrAMd7CrMKsehNpJ3SIl0Q3XdMWl0Pz+B1n+dq0uaZ8n3ydP3i94DnvyNM8veT789uFp8mvEOecEAABgpM56AAAAoLZRRgAAgCnKCAAAMEUZAQAApigjAADAFGUEAACYoowAAABTlBEAAGBqm/UA7lYoFLSwsKDGxkZFIhHr4eAenHNaWlpSMplUXZ133ZYcVBc/ckAGqgtzAbaSgcCVkYWFBbW0tFgPA2VKp9Pas2ePZ89HDqqTlzkgA9WJuQCbyYBvZWRsbEzHjx9XJpNRe3u7Tp06pY6Ojnv+XGNjoyTp7bffVjQa9Wt48Eg+n9dHH31UvG7/tNkMSOSg2viRAzJQXZgL8F8ZuBdfysi5c+fU19en8fFxdXZ2anR0VN3d3ZqdndWDDz74nz975zZcNBoleFXk7tunW8nAP5+PHFQXL3NABqoTcwE28+s0Xz7AeuLECb3++us6fPiwHn/8cY2Pj+v+++/XJ5984sfpEEBkABI5ABlAaTwvIysrK7p8+bJSqdT/T1JXp1QqpampqXXH5/N55XK5NRuqW7kZkMhBGDEXgLkApfK8jFy/fl2rq6uKx+Nr9sfjcWUymXXHDw8PKxaLFTc+qFT9ys2ARA7CiLkAzAUolfk6I/39/VpcXCxu6XTaekgwQA5ABiCRg1rl+QdYd+3apfr6emWz2TX7s9msEonEuuP5UFL4lJsBiRyEEXMBmAtQKs/vjDQ0NGjfvn2anJws7isUCpqcnFRXV5fXp0MAkQFI5ABkAKXz5au9fX196u3t1TPPPKOOjg6Njo5qeXlZhw8f9uN0CCAyAIkcgAygNL6UkVdeeUV//PGHBgcHlclk9PTTT+v8+fPrPsS0VUePHvXsOC+fq5zjgmwrr6FSGZBscuA1i/xVIstBmwsszslcELy5IMjCOhfci28rsB45ckRHjhzx6+lRBcgAJHIAMoB7M/82DQAAqG2UEQAAYIoyAgAATFFGAACAKcoIAAAwRRkBAACmKCMAAMAUZQQAAJjybdEzlCYMKwbWIq5bsHh5PViFt3oF+fUEeWxBwJ0RAABgijICAABMUUYAAIApyggAADBFGQEAAKYoIwAAwBRlBAAAmKKMAAAAUyx6VqagL4hU7ecMm1rKiyWvFwxDdQrD9fX6NVTLe8KdEQAAYIoyAgAATFFGAACAKcoIAAAwRRkBAACmKCMAAMAUZQQAAJiijAAAAFOUEQAAYIoVWMsUhhU1q2VFvjCwWk2RaxwcQb4WQR7bZoTt9fwXL+eCILxv3BkBAACmKCMAAMAUZQQAAJiijAAAAFOUEQAAYIoyAgAATFFGAACAKcoIAAAwRRkBAACmWIG1TKyoGTyRSKSk45xznp0z6NeDFXs3VsprsciTZDe3VPq5/FQt48R6nt8ZOXr0qCKRyJrtscce8/o0CDAyAIkcgAygdL7cGXniiSf01Vdf/f8k27gBU2vIACRyADKA0viSim3btimRSPjx1KgSZAASOQAZQGl8+QDr3NycksmkHnnkEb322mu6du3avx6bz+eVy+XWbKh+5WRAIgdhxVwA5gKUwvMy0tnZqdOnT+v8+fP6+OOPNT8/r+eee05LS0sbHj88PKxYLFbcWlpavB4SKqzcDEjkIIyYC8BcgFJ5XkZ6enr08ssv66mnnlJ3d7e+/PJL3bx5U5999tmGx/f392txcbG4pdNpr4eECis3AxI5CCPmAjAXoFS+f5KoqalJjz76qK5cubLh49FoVNFo1O9hwNC9MiCRg1rAXADmAvwb3xc9u3Xrln755Rc1Nzf7fSoEFBmARA5ABvDvPC8j77zzjr7++mv9+uuv+uabb/Tiiy+qvr5ehw4d8vpUCCgyAIkcgAygdJ7/mua3337ToUOHdOPGDe3evVvPPvusLl26pN27d3t9KhNBX+GvlPH5/RoqnYGhoaGSjgv6tSuFlyv2hi0HpSjlNZe6smrQ81SLGbBYddbquLDxvIycPXvW66dElSEDkMgByABKxx/KAwAApigjAADAFGUEAACYoowAAABTlBEAAGCKMgIAAExRRgAAgCnKCAAAMOX7H8oLG69Xx6vV1fa8FIb3MAyvARvj2lZOGN7rWv0/hjsjAADAFGUEAACYoowAAABTlBEAAGCKMgIAAExRRgAAgCnKCAAAMEUZAQAApigjAADAFCuwlslqNbtqWUXPgpfvTanP5fVxCI6gr4BpkfdqEYb3xuK8kUikpOOGhoZ8GwN3RgAAgCnKCAAAMEUZAQAApigjAADAFGUEAACYoowAAABTlBEAAGCKMgIAAEzVxKJnpSwiU+qiL865LY4GXgvDwk1heA3VoJbe5zAsAFauahmnF4K82ONmcGcEAACYoowAAABTlBEAAGCKMgIAAExRRgAAgCnKCAAAMEUZAQAApigjAADAFGUEAACYiriALSmay+UUi8X07rvvKhqNWg8H95DP5zUyMqLFxUXt3LnTs+clB9XFjxyQgerCXICtZKDsOyMXL17UgQMHlEwmFYlENDExseZx55wGBwfV3Nys7du3K5VKaW5urtzTIMCuXr2qM2fO6MMPP9TIyMi6x8lA+P0zA++//75+/vnnNY+TgdrAXACvlF1GlpeX1d7errGxsQ0fP3bsmE6ePKnx8XFNT09rx44d6u7u1u3bt7c8WATDysqK4vG4nn/++Q0fJwPhRwYgkQN4p+w/lNfT06Oenp4NH3POaXR0VO+9954OHjwoSfr0008Vj8c1MTGhV199dWujRSC0tbWpra1tw8fIQG0gA5DIAbzj6QdY5+fnlclklEqlivtisZg6Ozs1NTW14c/k83nlcrk1G6rXZjIgkYMwIQOQyAHK42kZyWQykqR4PL5mfzweLz52t+HhYcViseLW0tLi5ZBQYZvJgEQOwoQMQCIHKI/5V3v7+/u1uLhY3NLptPWQYIAcgAxAIge1ytMykkgkJEnZbHbN/mw2W3zsbtFoVDt37lyzoXptJgMSOQgTMgCJHKA8npaR1tZWJRIJTU5OFvflcjlNT0+rq6vLy1MhoMgAyAAkcoDylP1tmlu3bunKlSvFf8/Pz+v777/XAw88oL179+qtt97SBx98oLa2NrW2tmpgYEDJZFIvvPBCSc9/Zw22fD5f7tBQISsrK/rzzz/X7Pvhhx/00EMPeZIBiRwE3d0ZuHHjhiTp2rVrevLJJ8lAjWAuwD/duUabWkvVlenChQtO0rqtt7fXOedcoVBwAwMDLh6Pu2g06vbv3+9mZ2dLfv50Or3h87MFf/MqA+SgereXXnqJDLAxF9T4lk6ny7rGzjkXuOXgC4WCFhYW1NjYqEgkIunvW3stLS1Kp9P8/tDQRtfBOaelpSUlk0nV1Xn3Wz9yEFyVygEZCC7LuYAMBIPXGSj71zR+q6ur0549ezZ8jA8zBcPd1yEWi3l+DnIQfH7ngAwEn+VcQAaCwasMmH+1FwAA1DbKCAAAMFUVZSQajWpoaIg/H23M+jpYnx9/s7wOZCAYyAC8vg6B+wArAACoLVVxZwQAAIQXZQQAAJiijAAAAFOUEQAAYKoqysjY2Jgefvhh3Xfffers7NS3335rPaRQu3jxog4cOKBkMqlIJKKJiYk1jzvnNDg4qObmZm3fvl2pVEpzc3O+jokMVFYQMyCRg0oLYg7IQGVVKgOBLyPnzp1TX1+fhoaG9N1336m9vV3d3d36/fffrYcWWsvLy2pvb9fY2NiGjx87dkwnT57U+Pi4pqentWPHDnV3d+v27du+jIcMVF7QMiCRAwtBywEZqLyKZaDsv2ZTYR0dHe7NN98s/nt1ddUlk0k3PDxsOKraIcl9/vnnxX8XCgWXSCTc8ePHi/tu3rzpotGoO3PmjC9jIAO2gpAB58iBtSDkgAzY8jMDgb4zsrKyosuXLyuVShX31dXVKZVKaWpqynBktWt+fl6ZTGbNNYnFYurs7PTlmpCB4Kl0BiRyEETMBfAyA4EuI9evX9fq6qri8fia/fF4XJlMxmhUte3O+16pa0IGgqfSGZDIQRAxF8DLDAS6jAAAgPALdBnZtWuX6uvrlc1m1+zPZrNKJBJGo6ptd973Sl0TMhA8lc6ARA6CiLkAXmYg0GWkoaFB+/bt0+TkZHFfoVDQ5OSkurq6DEdWu1pbW5VIJNZck1wup+npaV+uCRkInkpnQCIHQcRcAE8z4NWnbP1y9uxZF41G3enTp91PP/3k3njjDdfU1OQymYz10EJraWnJzczMuJmZGSfJnThxws3MzLirV68655wbGRlxTU1N7osvvnA//vijO3jwoGttbXV//fWXL+MhA5UXtAw4Rw4sBC0HZKDyKpWBwJcR55w7deqU27t3r2toaHAdHR3u0qVL1kMKtQsXLjhJ67be3l7n3N9f5xoYGHDxeNxFo1G3f/9+Nzs76+uYyEBlBTEDzpGDSgtiDshAZVUqAxHnnNvkHRoAAIAtC/RnRgAAQPhRRgAAgCnKCAAAMEUZAQAApigjAADAFGUEAACYoowAAABTlBEAAGCKMgIAAExRRgAAgCnKCAAAMEUZAQAApv4HJSE3vhejPs4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the dataloader\n",
    "dataiter = iter(trainLoader)\n",
    "this_iter = next(dataiter)\n",
    "this_iter['data'], this_iter['label']\n",
    "# mazes, filenames, labels = next(dataiter)\n",
    "# mazes\n",
    "# this_iter\n",
    "\n",
    "fig, axes = plt.subplots(1,4)\n",
    "axes[0].imshow(this_iter['data'][0].numpy(), cmap='binary')\n",
    "axes[1].imshow(this_iter['data'][1].numpy(), cmap='binary')\n",
    "axes[2].imshow(this_iter['data'][2].numpy(), cmap='binary')\n",
    "axes[3].imshow(this_iter['data'][3].numpy(), cmap='binary')\n",
    "\n",
    "this_iter['label'][0], this_iter['label'][1], this_iter['label'][2], this_iter['label'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(6, 6), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=16, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=5, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 6, 6, 6]             222\n",
      "         MaxPool2d-2              [-1, 6, 3, 3]               0\n",
      "            Conv2d-3             [-1, 16, 2, 2]             400\n",
      "         MaxPool2d-4             [-1, 16, 1, 1]               0\n",
      "            Linear-5                  [-1, 120]           2,040\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                    [-1, 5]             425\n",
      "================================================================\n",
      "Total params: 13,251\n",
      "Trainable params: 13,251\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.06\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 6)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 2)\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "n = 11\n",
    "summary(net, (1,n,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.784\n",
      "[1,  4000] loss: 0.715\n",
      "[1,  6000] loss: 0.667\n",
      "[1,  8000] loss: 0.589\n",
      "[1, 10000] loss: 0.553\n",
      "[1, 12000] loss: 0.515\n",
      "[1, 14000] loss: 0.471\n",
      "[1, 16000] loss: 0.445\n",
      "[1, 18000] loss: 0.426\n",
      "[1, 20000] loss: 0.416\n",
      "[1, 22000] loss: 0.390\n",
      "[1, 24000] loss: 0.379\n",
      "[1, 26000] loss: 0.384\n",
      "[1, 28000] loss: 0.365\n",
      "[1, 30000] loss: 0.361\n",
      "[1, 32000] loss: 0.345\n",
      "[1, 34000] loss: 0.340\n",
      "[1, 36000] loss: 0.331\n",
      "[1, 38000] loss: 0.325\n",
      "[1, 40000] loss: 0.341\n",
      "[1, 42000] loss: 0.320\n",
      "[1, 44000] loss: 0.324\n",
      "[1, 46000] loss: 0.325\n",
      "[1, 48000] loss: 0.315\n",
      "[1, 50000] loss: 0.304\n",
      "[1, 52000] loss: 0.305\n",
      "[1, 54000] loss: 0.298\n",
      "[1, 56000] loss: 0.303\n",
      "[1, 58000] loss: 0.301\n",
      "[1, 60000] loss: 0.299\n",
      "[2,  2000] loss: 0.297\n",
      "[2,  4000] loss: 0.300\n",
      "[2,  6000] loss: 0.294\n",
      "[2,  8000] loss: 0.276\n",
      "[2, 10000] loss: 0.299\n",
      "[2, 12000] loss: 0.298\n",
      "[2, 14000] loss: 0.285\n",
      "[2, 16000] loss: 0.270\n",
      "[2, 18000] loss: 0.290\n",
      "[2, 20000] loss: 0.270\n",
      "[2, 22000] loss: 0.283\n",
      "[2, 24000] loss: 0.269\n",
      "[2, 26000] loss: 0.283\n",
      "[2, 28000] loss: 0.273\n",
      "[2, 30000] loss: 0.266\n",
      "[2, 32000] loss: 0.263\n",
      "[2, 34000] loss: 0.267\n",
      "[2, 36000] loss: 0.263\n",
      "[2, 38000] loss: 0.260\n",
      "[2, 40000] loss: 0.276\n",
      "[2, 42000] loss: 0.249\n",
      "[2, 44000] loss: 0.271\n",
      "[2, 46000] loss: 0.267\n",
      "[2, 48000] loss: 0.262\n",
      "[2, 50000] loss: 0.265\n",
      "[2, 52000] loss: 0.254\n",
      "[2, 54000] loss: 0.254\n",
      "[2, 56000] loss: 0.250\n",
      "[2, 58000] loss: 0.252\n",
      "[2, 60000] loss: 0.259\n",
      "[3,  2000] loss: 0.255\n",
      "[3,  4000] loss: 0.247\n",
      "[3,  6000] loss: 0.258\n",
      "[3,  8000] loss: 0.249\n",
      "[3, 10000] loss: 0.250\n",
      "[3, 12000] loss: 0.237\n",
      "[3, 14000] loss: 0.246\n",
      "[3, 16000] loss: 0.249\n",
      "[3, 18000] loss: 0.247\n",
      "[3, 20000] loss: 0.242\n",
      "[3, 22000] loss: 0.250\n",
      "[3, 24000] loss: 0.253\n",
      "[3, 26000] loss: 0.231\n",
      "[3, 28000] loss: 0.243\n",
      "[3, 30000] loss: 0.238\n",
      "[3, 32000] loss: 0.243\n",
      "[3, 34000] loss: 0.239\n",
      "[3, 36000] loss: 0.235\n",
      "[3, 38000] loss: 0.245\n",
      "[3, 40000] loss: 0.237\n",
      "[3, 42000] loss: 0.230\n",
      "[3, 44000] loss: 0.234\n",
      "[3, 46000] loss: 0.244\n",
      "[3, 48000] loss: 0.231\n",
      "[3, 50000] loss: 0.234\n",
      "[3, 52000] loss: 0.233\n",
      "[3, 54000] loss: 0.235\n",
      "[3, 56000] loss: 0.227\n",
      "[3, 58000] loss: 0.230\n",
      "[3, 60000] loss: 0.232\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, current_data in enumerate(trainLoader, 0):\n",
    "    # for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs, labels = data\n",
    "        # print(current_data)\n",
    "        inputs = current_data[\"data\"].float().reshape(-1, 1, n, n)\n",
    "        # print(inputs.shape)\n",
    "        labels = current_data[\"label\"]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './maze_net11x11_even_label.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display an image from the test set to get familiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load back in our saved model (note: saving and re-loading the model wasnâ€™t necessary here, we only did it to illustrate how to do so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0), tensor(4), tensor(2))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter_test = iter(testLoader)\n",
    "this_iter_test = next(dataiter_test)\n",
    "\n",
    "fig, axes = plt.subplots(1,4)\n",
    "axes[0].imshow(this_iter_test['data'][0].numpy(), cmap='binary')\n",
    "axes[1].imshow(this_iter_test['data'][1].numpy(), cmap='binary')\n",
    "axes[2].imshow(this_iter_test['data'][2].numpy(), cmap='binary')\n",
    "axes[3].imshow(this_iter_test['data'][3].numpy(), cmap='binary')\n",
    "\n",
    "this_iter_test['label'][0], this_iter_test['label'][1], this_iter_test['label'][2], this_iter_test['label'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.1255,  2.8925,  0.7624, -7.7462, -7.9402],\n",
       "        [12.9885,  3.4462, -0.3942, -8.0632, -5.9413],\n",
       "        [-9.1665, -1.3884,  1.7136,  0.8412,  9.4210],\n",
       "        [-4.7047, -3.3629, 13.2428,  1.1882, -3.6862]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = net(this_iter_test[\"data\"].float().reshape(-1,1,n,n))\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  END   END   DOWN  RIGHT\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at how the network performs on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test mazes: 90 %\n",
      "The F1 Score is: 0.9040599453552239\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "f1_true = None\n",
    "f1_predicted = None\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for current_data in testLoader:\n",
    "        mazes = current_data['data'].float().reshape(-1,1,n,n)\n",
    "        labels = current_data['label']\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(mazes)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if f1_true is None:\n",
    "            f1_true = labels.detach().numpy()\n",
    "            f1_predicted = predicted.detach().numpy()\n",
    "        else:\n",
    "            f1_true = np.concatenate((f1_true, labels.detach().numpy()))\n",
    "            f1_predicted = np.concatenate((f1_predicted, predicted.detach().numpy()))\n",
    "\n",
    "print(f'Accuracy of the network on the test mazes: {100 * correct // total} %')\n",
    "\n",
    "# F1 score\n",
    "score = f1_score(f1_true, f1_predicted, average=\"macro\")\n",
    "print(f\"The F1 Score is: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, what are the classes that performed well, and the classes that did not perform well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: END   is 100.0 %\n",
      "Accuracy for class: LEFT  is 95.2 %\n",
      "Accuracy for class: RIGHT is 90.0 %\n",
      "Accuracy for class: UP    is 91.1 %\n",
      "Accuracy for class: DOWN  is 76.1 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for current_data in testLoader:\n",
    "        mazes = current_data['data'].float().reshape(-1,1,n,n)\n",
    "        labels = current_data['label']\n",
    "        outputs = net(mazes)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            # print(label, prediction)\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "# print(total_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mazerl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
