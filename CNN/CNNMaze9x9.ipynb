{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "import math\n",
    "from datasets import Dataset, Features, Array2D, Value, load_dataset, load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 3)\n",
      "{'data': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 2, 1, 0, 0, 0, 0, 0, 1],\n",
      "        [1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
      "        [1, 0, 1, 1, 1, 0, 1, 0, 1],\n",
      "        [1, 0, 0, 0, 0, 0, 1, 0, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'filename': '/Users/victoriachong/Documents/SUTD/TERM 8/50.021 Artificial Intelligence/maze-puzzle/dataset/2.0/9x9/train_set9HnKgridsize_1_step0_DOWN', 'label': tensor(4)}\n"
     ]
    }
   ],
   "source": [
    "loaded_data = load_from_disk(\n",
    "        \"/Users/yijiachen/Desktop/50.021 Artificial Intelligence/Project/code/code-repo/dataset/even_label/9x9.hf\"\n",
    "    ).with_format(\"torch\")\n",
    "\n",
    "print(loaded_data.shape)\n",
    "print(loaded_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "train_set_size = math.floor(0.8*loaded_data.shape[0])\n",
    "train_set, val_set = torch.utils.data.random_split(loaded_data, [train_set_size, loaded_data.shape[0] - train_set_size])\n",
    "trainLoader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True)\n",
    "testLoader = torch.utils.data.DataLoader(val_set, batch_size=4, shuffle=False)\n",
    "\n",
    "classes = ('END', 'LEFT', 'RIGHT', 'UP', 'DOWN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2), tensor(4), tensor(4), tensor(3))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the dataloader\n",
    "dataiter = iter(trainLoader)\n",
    "this_iter = next(dataiter)\n",
    "this_iter['data'], this_iter['label']\n",
    "# mazes, filenames, labels = next(dataiter)\n",
    "# mazes\n",
    "# this_iter\n",
    "\n",
    "fig, axes = plt.subplots(1,4)\n",
    "axes[0].imshow(this_iter['data'][0].numpy(), cmap='binary')\n",
    "axes[1].imshow(this_iter['data'][1].numpy(), cmap='binary')\n",
    "axes[2].imshow(this_iter['data'][2].numpy(), cmap='binary')\n",
    "axes[3].imshow(this_iter['data'][3].numpy(), cmap='binary')\n",
    "\n",
    "this_iter['label'][0], this_iter['label'][1], this_iter['label'][2], this_iter['label'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the neural network from the Neural Networks section before and modify it to take 3-channel images (instead of 1-channel images as it was defined)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(4, 4), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=16, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=5, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1              [-1, 6, 6, 6]             102\n",
      "         MaxPool2d-2              [-1, 6, 3, 3]               0\n",
      "            Conv2d-3             [-1, 16, 2, 2]             400\n",
      "         MaxPool2d-4             [-1, 16, 1, 1]               0\n",
      "            Linear-5                  [-1, 120]           2,040\n",
      "            Linear-6                   [-1, 84]          10,164\n",
      "            Linear-7                    [-1, 5]             425\n",
      "================================================================\n",
      "Total params: 13,131\n",
      "Trainable params: 13,131\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.05\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 4)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 2)\n",
    "        self.fc1 = nn.Linear(16 * 1 * 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "n = 9\n",
    "summary(net, (1,n,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s use a Classification Cross-Entropy loss and SGD with momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  1000] loss: 0.421\n",
      "[1,  2000] loss: 0.389\n",
      "[1,  3000] loss: 0.358\n",
      "[1,  4000] loss: 0.365\n",
      "[1,  5000] loss: 0.341\n",
      "[1,  6000] loss: 0.314\n",
      "[1,  7000] loss: 0.311\n",
      "[1,  8000] loss: 0.299\n",
      "[1,  9000] loss: 0.265\n",
      "[1, 10000] loss: 0.266\n",
      "[1, 11000] loss: 0.245\n",
      "[1, 12000] loss: 0.231\n",
      "[1, 13000] loss: 0.216\n",
      "[1, 14000] loss: 0.202\n",
      "[1, 15000] loss: 0.185\n",
      "[1, 16000] loss: 0.200\n",
      "[1, 17000] loss: 0.184\n",
      "[1, 18000] loss: 0.176\n",
      "[1, 19000] loss: 0.179\n",
      "[1, 20000] loss: 0.163\n",
      "[1, 21000] loss: 0.176\n",
      "[1, 22000] loss: 0.151\n",
      "[1, 23000] loss: 0.146\n",
      "[1, 24000] loss: 0.155\n",
      "[1, 25000] loss: 0.151\n",
      "[1, 26000] loss: 0.158\n",
      "[1, 27000] loss: 0.135\n",
      "[1, 28000] loss: 0.141\n",
      "[1, 29000] loss: 0.131\n",
      "[1, 30000] loss: 0.134\n",
      "[1, 31000] loss: 0.118\n",
      "[1, 32000] loss: 0.143\n",
      "[1, 33000] loss: 0.125\n",
      "[1, 34000] loss: 0.134\n",
      "[1, 35000] loss: 0.132\n",
      "[1, 36000] loss: 0.118\n",
      "[1, 37000] loss: 0.117\n",
      "[1, 38000] loss: 0.115\n",
      "[1, 39000] loss: 0.120\n",
      "[1, 40000] loss: 0.120\n",
      "[1, 41000] loss: 0.116\n",
      "[1, 42000] loss: 0.125\n",
      "[1, 43000] loss: 0.108\n",
      "[1, 44000] loss: 0.110\n",
      "[1, 45000] loss: 0.113\n",
      "[1, 46000] loss: 0.114\n",
      "[1, 47000] loss: 0.107\n",
      "[1, 48000] loss: 0.110\n",
      "[1, 49000] loss: 0.099\n",
      "[1, 50000] loss: 0.103\n",
      "[2,  1000] loss: 0.100\n",
      "[2,  2000] loss: 0.124\n",
      "[2,  3000] loss: 0.117\n",
      "[2,  4000] loss: 0.112\n",
      "[2,  5000] loss: 0.104\n",
      "[2,  6000] loss: 0.090\n",
      "[2,  7000] loss: 0.081\n",
      "[2,  8000] loss: 0.108\n",
      "[2,  9000] loss: 0.087\n",
      "[2, 10000] loss: 0.106\n",
      "[2, 11000] loss: 0.098\n",
      "[2, 12000] loss: 0.099\n",
      "[2, 13000] loss: 0.094\n",
      "[2, 14000] loss: 0.088\n",
      "[2, 15000] loss: 0.088\n",
      "[2, 16000] loss: 0.082\n",
      "[2, 17000] loss: 0.106\n",
      "[2, 18000] loss: 0.080\n",
      "[2, 19000] loss: 0.086\n",
      "[2, 20000] loss: 0.099\n",
      "[2, 21000] loss: 0.090\n",
      "[2, 22000] loss: 0.088\n",
      "[2, 23000] loss: 0.087\n",
      "[2, 24000] loss: 0.085\n",
      "[2, 25000] loss: 0.091\n",
      "[2, 26000] loss: 0.083\n",
      "[2, 27000] loss: 0.085\n",
      "[2, 28000] loss: 0.076\n",
      "[2, 29000] loss: 0.087\n",
      "[2, 30000] loss: 0.087\n",
      "[2, 31000] loss: 0.084\n",
      "[2, 32000] loss: 0.092\n",
      "[2, 33000] loss: 0.093\n",
      "[2, 34000] loss: 0.092\n",
      "[2, 35000] loss: 0.075\n",
      "[2, 36000] loss: 0.068\n",
      "[2, 37000] loss: 0.079\n",
      "[2, 38000] loss: 0.071\n",
      "[2, 39000] loss: 0.078\n",
      "[2, 40000] loss: 0.072\n",
      "[2, 41000] loss: 0.083\n",
      "[2, 42000] loss: 0.073\n",
      "[2, 43000] loss: 0.085\n",
      "[2, 44000] loss: 0.080\n",
      "[2, 45000] loss: 0.069\n",
      "[2, 46000] loss: 0.084\n",
      "[2, 47000] loss: 0.074\n",
      "[2, 48000] loss: 0.076\n",
      "[2, 49000] loss: 0.071\n",
      "[2, 50000] loss: 0.083\n",
      "[3,  1000] loss: 0.075\n",
      "[3,  2000] loss: 0.084\n",
      "[3,  3000] loss: 0.070\n",
      "[3,  4000] loss: 0.075\n",
      "[3,  5000] loss: 0.069\n",
      "[3,  6000] loss: 0.084\n",
      "[3,  7000] loss: 0.074\n",
      "[3,  8000] loss: 0.063\n",
      "[3,  9000] loss: 0.072\n",
      "[3, 10000] loss: 0.074\n",
      "[3, 11000] loss: 0.065\n",
      "[3, 12000] loss: 0.068\n",
      "[3, 13000] loss: 0.058\n",
      "[3, 14000] loss: 0.085\n",
      "[3, 15000] loss: 0.075\n",
      "[3, 16000] loss: 0.075\n",
      "[3, 17000] loss: 0.070\n",
      "[3, 18000] loss: 0.069\n",
      "[3, 19000] loss: 0.078\n",
      "[3, 20000] loss: 0.073\n",
      "[3, 21000] loss: 0.064\n",
      "[3, 22000] loss: 0.065\n",
      "[3, 23000] loss: 0.070\n",
      "[3, 24000] loss: 0.071\n",
      "[3, 25000] loss: 0.068\n",
      "[3, 26000] loss: 0.068\n",
      "[3, 27000] loss: 0.076\n",
      "[3, 28000] loss: 0.056\n",
      "[3, 29000] loss: 0.074\n",
      "[3, 30000] loss: 0.065\n",
      "[3, 31000] loss: 0.078\n",
      "[3, 32000] loss: 0.071\n",
      "[3, 33000] loss: 0.062\n",
      "[3, 34000] loss: 0.062\n",
      "[3, 35000] loss: 0.073\n",
      "[3, 36000] loss: 0.060\n",
      "[3, 37000] loss: 0.063\n",
      "[3, 38000] loss: 0.061\n",
      "[3, 39000] loss: 0.057\n",
      "[3, 40000] loss: 0.072\n",
      "[3, 41000] loss: 0.069\n",
      "[3, 42000] loss: 0.063\n",
      "[3, 43000] loss: 0.053\n",
      "[3, 44000] loss: 0.076\n",
      "[3, 45000] loss: 0.058\n",
      "[3, 46000] loss: 0.056\n",
      "[3, 47000] loss: 0.065\n",
      "[3, 48000] loss: 0.060\n",
      "[3, 49000] loss: 0.064\n",
      "[3, 50000] loss: 0.055\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, current_data in enumerate(trainLoader, 0):\n",
    "    # for i, data in enumerate(trainLoader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs, labels = data\n",
    "        # print(current_data)\n",
    "        inputs = current_data[\"data\"].float().reshape(-1, 1, n, n)\n",
    "        # print(inputs.shape)\n",
    "        labels = current_data[\"label\"]\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 1000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './maze_net9x9_even_label.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display an image from the test set to get familiar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load back in our saved model (note: saving and re-loading the model wasn’t necessary here, we only did it to illustrate how to do so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(3), tensor(0), tensor(4))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter_test = iter(testLoader)\n",
    "this_iter_test = next(dataiter_test)\n",
    "\n",
    "fig, axes = plt.subplots(1,4)\n",
    "axes[0].imshow(this_iter_test['data'][0].numpy(), cmap='binary')\n",
    "axes[1].imshow(this_iter_test['data'][1].numpy(), cmap='binary')\n",
    "axes[2].imshow(this_iter_test['data'][2].numpy(), cmap='binary')\n",
    "axes[3].imshow(this_iter_test['data'][3].numpy(), cmap='binary')\n",
    "\n",
    "this_iter_test['label'][0], this_iter_test['label'][1], this_iter_test['label'][2], this_iter_test['label'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  DOWN  END   UP    END  \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join(f'{classes[predicted[j]]:5s}'\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at how the network performs on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "f1_true = None\n",
    "f1_predicted = None\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for current_data in testLoader:\n",
    "        mazes = current_data['data'].float().reshape(-1,1,n,n)\n",
    "        labels = current_data['label']\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(mazes)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        if f1_true is None:\n",
    "            f1_true = labels.detach().numpy()\n",
    "            f1_predicted = predicted.detach().numpy()\n",
    "        else:\n",
    "            f1_true = np.concatenate((f1_true, labels.detach().numpy()))\n",
    "            f1_predicted = np.concatenate((f1_predicted, predicted.detach().numpy()))\n",
    "\n",
    "print(f'Accuracy of the network on the test mazes: {100 * correct // total} %')\n",
    "\n",
    "# F1 score\n",
    "score = f1_score(f1_true, f1_predicted, average=\"macro\")\n",
    "print(f\"The F1 Score is: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The F1 Score is: 0.9743766289125382\n"
     ]
    }
   ],
   "source": [
    "# F1 score\n",
    "score = f1_score(f1_true, f1_predicted, average=\"macro\")\n",
    "print(f\"The F1 Score is: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm, what are the classes that performed well, and the classes that did not perform well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class: END   is 100.0 %\n",
      "Accuracy for class: LEFT  is 99.6 %\n",
      "Accuracy for class: RIGHT is 92.1 %\n",
      "Accuracy for class: UP    is 99.2 %\n",
      "Accuracy for class: DOWN  is 96.4 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for current_data in testLoader:\n",
    "        mazes = current_data['data'].float().reshape(-1,1,n,n)\n",
    "        labels = current_data['label']\n",
    "        outputs = net(mazes)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            # print(label, prediction)\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
    "\n",
    "# print(total_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mazerl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
